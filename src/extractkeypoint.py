import cv2
import mediapipe as mp
import numpy as np
import os

mp_holistic = mp.solutions.holistic


def mediapipe_process(image, model):
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_rgb.flags.writeable = False
    results = model.process(image_rgb)
    image_rgb.flags.writeable = True
    return results


def extract_keypoints(results, prev_lh=None, prev_rh=None):
    """
    ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ó‡∏ò‡πå Dimension: 258
    üî• ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≥‡∏Ñ‡πà‡∏≤‡∏°‡∏∑‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (Forward Fill) ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏£‡πå‡∏õ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
    """
    ref_x, ref_y, ref_z = 0.5, 0.5, 0.0
    body_size = 1.0

    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        ref_x = (landmarks[11].x + landmarks[12].x) / 2
        ref_y = (landmarks[11].y + landmarks[12].y) / 2
        ref_z = (landmarks[11].z + landmarks[12].z) / 2

        dist_x = landmarks[11].x - landmarks[12].x
        dist_y = landmarks[11].y - landmarks[12].y
        body_size = np.sqrt(dist_x**2 + dist_y**2)

        if body_size < 0.001:
            body_size = 1.0

    def get_relative_coords(landmarks_obj, is_pose=False, prev_state=None):
        if not landmarks_obj:
            # üî• ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô ‡∏°‡∏∑‡∏≠‡∏´‡∏≤‡∏¢) ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if prev_state is not None and np.any(prev_state != 0):
                return prev_state
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏®‡∏π‡∏ô‡∏¢‡πå (‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏•‡∏¥‡∏õ‡∏°‡∏≤‡∏Å‡πá‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏°‡∏∑‡∏≠‡πÄ‡∏•‡∏¢)
            return np.zeros(33 * 4) if is_pose else np.zeros(21 * 3)

        data = []
        for res in landmarks_obj.landmark:
            rel_x = (res.x - ref_x) / body_size
            rel_y = (res.y - ref_y) / body_size
            rel_z = (res.z - ref_z) / body_size

            if is_pose:
                data.append([rel_x, rel_y, rel_z, res.visibility])
            else:
                data.append([rel_x, rel_y, rel_z])

        return np.array(data).flatten()

    pose = get_relative_coords(results.pose_landmarks, is_pose=True)
    lh = get_relative_coords(
        results.left_hand_landmarks, is_pose=False, prev_state=prev_lh
    )
    rh = get_relative_coords(
        results.right_hand_landmarks, is_pose=False, prev_state=prev_rh
    )

    return np.concatenate([pose, lh, rh]), lh, rh


# --- Config ‡∏´‡∏•‡∏±‡∏Å ---
RAW_DATA_PATH = os.path.join("data", "raw")
PROCESSED_DATA_PATH = os.path.join("data", "processed")

# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á
actions = np.array(
    [
        # "anxiety",
        # "fever",
        # "feverish",
        # "insomnia",
        # "itching",
        # "no_action",
        # "polyuria",
        # "suffocated",
        # "wounded",
        "breathing_difficulty_p",
        # "fever_p",
        # "polyuria_p",
    ]
)



sequence_length = 30
num_features = 258

for action in actions:
    os.makedirs(os.path.join(PROCESSED_DATA_PATH, action), exist_ok=True)
print(f"Ensured '{PROCESSED_DATA_PATH}' folders exist.")

print("--- Starting Video Preprocessing ---")

# üî• ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î: ‡πÉ‡∏ä‡πâ model_complexity=2 ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ Tracker
with mp_holistic.Holistic(
    static_image_mode=False,  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö False ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Tracking ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô
    model_complexity=2,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î
    smooth_landmarks=True,  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏ô
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5,
) as holistic:

    for action in actions:
        action_raw_path = os.path.join(RAW_DATA_PATH, action)
        action_processed_path = os.path.join(PROCESSED_DATA_PATH, action)

        if not os.path.exists(action_raw_path):
            continue

        video_files = [
            f
            for f in os.listdir(action_raw_path)
            if f.endswith((".mp4", ".avi", ".mov"))
        ]
        print(f"\nProcessing Action: '{action}' ({len(video_files)} videos found)")

        for sequence_idx, video_file in enumerate(video_files):
            video_path = os.path.join(action_raw_path, video_file)
            cap = cv2.VideoCapture(video_path)

            all_frames_data = []  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏∏‡∏Å‡πÄ‡∏ü‡∏£‡∏°‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô

            # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≥‡∏Ñ‡πà‡∏≤‡∏°‡∏∑‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
            prev_lh = np.zeros(21 * 3)
            prev_rh = np.zeros(21 * 3)

            # üî• ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î: ‡∏≠‡πà‡∏≤‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏Ç‡πâ‡∏≤‡∏°) Tracker ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏û‡∏±‡∏á
            while True:
                success, frame = cap.read()
                if not success:
                    break
                # Mirror
                frame = cv2.flip(frame, 1)
                results = mediapipe_process(frame, holistic)

                # ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ prev_lh, prev_rh ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
                keypoints, prev_lh, prev_rh = extract_keypoints(
                    results, prev_lh, prev_rh
                )
                all_frames_data.append(keypoints)

            cap.release()

            # üî• ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡πÄ‡∏ü‡∏£‡∏° ‡∏Ñ‡πà‡∏≠‡∏¢‡∏°‡∏≤ Sample ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 30 ‡πÄ‡∏ü‡∏£‡∏°
            total_extracted = len(all_frames_data)
            if total_extracted < sequence_length:
                print(
                    f"  [Warning] Video {video_file} is too short ({total_extracted} frames). Skipping."
                )
                continue

            # ‡∏î‡∏∂‡∏á index ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ 30 ‡πÄ‡∏ü‡∏£‡∏°‡∏û‡∏≠‡∏î‡∏µ
            frame_indices = np.linspace(
                0, total_extracted - 1, sequence_length, dtype=int
            )
            sequence_data = np.array(all_frames_data)[frame_indices]

            npy_path = os.path.join(action_processed_path, f"{sequence_idx}.npy")
            np.save(npy_path, sequence_data)

            print(
                f"\r  Processed {sequence_idx + 1}/{len(video_files)} videos...", end=""
            )

        print(f'\nAction "{action}" complete.')

print("\n--- Preprocessing Complete! ---")
